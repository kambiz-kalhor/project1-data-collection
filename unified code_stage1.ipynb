{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for the dear user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please give me the string of path for the file \"stage1_step1_export_bacdive_iso_table before cleaning.csv\"\n",
    "# for example  --->   r'C:\\Users\\kamy\\Desktop\\stage1_step1_export_bacdive_iso_table before cleaning.csv'\n",
    "input_path = r'C:\\Users\\kamy\\Desktop\\INPUT.csv'\n",
    "\n",
    "\n",
    "# and again please give me the output path to save the final result\n",
    "output_path = r'C:\\Users\\kamy\\Desktop\\OUTPUT.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing all the packages we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from pymed import PubMed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP ONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download a table from BacDive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i did it and the result is \"saved as stage1_step1_export_bacdive_iso_table before cleaning.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this file is our input and we rename it as 'INPUT.CSV'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can access it in git_hub repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP TWO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read stage1_step1_export_bacdive_iso_table before cleaning.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stage1_step1_export_bacdive_iso_table before cleaning.csv\n",
    "bacDive = pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the table # replacing NaN with no in three colums (Category 1, Category 2, Category 3)\n",
    "bacDive[\"Category 3\"].fillna(\"#no\", inplace = True)\n",
    "bacDive[\"Category 2\"].fillna(\"#no\", inplace = True)\n",
    "bacDive[\"Category 1\"].fillna(\"#no\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the reason i used this code is to fill empty cells\n",
    "# this code means --> check the IDs, if the ID of two consecutive rows are the same than fill the second row with the cells of first row\n",
    "\n",
    "temporary_list =[]\n",
    "x = len(bacDive['ID'])-1\n",
    "for counter in range(0,x):\n",
    "    if bacDive.iloc[counter,0] == bacDive.iloc[counter+1,0]:\n",
    "        temporary_list.append(counter)\n",
    "        bacDive.iloc[counter+1,1] = bacDive.iloc[counter,1]\n",
    "        bacDive.iloc[counter+1,2] = bacDive.iloc[counter,2]\n",
    "        bacDive.iloc[counter+1,3] = bacDive.iloc[counter,3]\n",
    "        bacDive.iloc[counter+1,4] = bacDive.iloc[counter,4]\n",
    "        bacDive.iloc[counter+1,5] = bacDive.iloc[counter,5]\n",
    "        \n",
    "        # we do not need the next code because we want to maintain the Tag data\n",
    "        #bacDive.iloc[counter+1,7] = bacDive.iloc[counter,7] +  bacDive.iloc[counter+1,7]\n",
    "        #bacDive.iloc[counter+1,8] = bacDive.iloc[counter,8] +  bacDive.iloc[counter+1,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## we wont need this if we are going to maintain other Tags in future\n",
    "######## this code is written to remove all the rows without a specific Tag(here : #Environmental)\n",
    "\n",
    "\n",
    "#temporary_list =[]\n",
    "#for counter in range (0,len(bacDive.index)):\n",
    "    #if (bacDive.iloc[counter,6] != '#Environmental') :\n",
    "        #temporary_list.append(counter)\n",
    "\n",
    "######## we run this code at the end in order to keep all other category 1 tags \n",
    "#for i in temporary_list:\n",
    "    #bacDive = bacDive.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have a dataframe whithout any tags other than #Environmental  but there are still some redundency, there are some rows with the same Species name\n",
    "# here the goal is to merge rows with the same Species name\n",
    "\n",
    "\n",
    "temporary_list =[]\n",
    "x = len(bacDive['ID'])-1\n",
    "for counter in range(0,x):\n",
    "    if bacDive.iloc[counter,0] == bacDive.iloc[counter+1,0]:\n",
    "        temporary_list.append(counter)\n",
    "        bacDive.iloc[counter+1,7] = bacDive.iloc[counter,7] +  bacDive.iloc[counter+1,7]\n",
    "        bacDive.iloc[counter+1,8] = bacDive.iloc[counter,8] +  bacDive.iloc[counter+1,8]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we remove the duplicate row (consecutive duplicated rows only)\n",
    "for i in temporary_list:\n",
    "    bacDive = bacDive.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the repeated species \n",
    "list_of_Indexes = []\n",
    "\n",
    "new_list_of_IDs =[]\n",
    "for i in bacDive.index:\n",
    "    if bacDive.loc[i,'ID'] not in new_list_of_IDs:\n",
    "        new_list_of_IDs.append(bacDive.loc[i,'ID'])\n",
    "    else:\n",
    "        list_of_Indexes.append(i)\n",
    "        \n",
    "        \n",
    "#bacDive = bacDive.drop(list_of_Indexes)\n",
    "\n",
    "#################################################################\n",
    "# i found a wired flaw in BacDive database : here in this code we remove the rows with the same species name \n",
    "# the result is a dataframe with 8681 row\n",
    "# now if we remove the rows with the same ID, the result will be a dataframe with 18040 rows\n",
    "# this means that there are some species with the same name but with different ID\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP THREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEB SCRAPING from BacDive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to creat URLs using the BacDive IDs\n",
    "all_IDs = bacDive['ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "producing links for web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ID_give_URL(ID):\n",
    "    url = 'https://bacdive.dsmz.de/strain/' + str(ID)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    return None\n",
    "#CODE = 200 means the url is availible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my regex to extract temperature data from BacDive\n",
    "# in future i should improve this regex \n",
    "my_regex_temperature = re.compile(\"(Ref\\.\\:.\\#\\d+)\\]\\<\\/a\\>\\<\\/td\\>\\s\\<td\\>\\<\\/td\\>\\s\\<td.class\\=\\\"border\\_rightfree\\ textalign\\_right\\\"\\>\\<\\/td\\>\\s\\<td.class\\=\\\"border\\_leftfree\\\"\\>(\\w+)\\<\\/td\\>\\s\\<td.class\\=\\\"border_leftfree textalign_center\\\"\\>(\\d{2}\\-\\d{2}|\\d{2}\\.\\d{1}|\\d{2})\")\n",
    "\n",
    "# my regex to extract pH data from BacDive\n",
    "# in future i should improve this regex \n",
    "x=str('(Ref\\.\\:.\\#\\d+)\\]\\<\\/a\\>\\<\\/td\\>\\\\n\\<td\\>\\<\\/td\\>\\\\n\\<td\\sclass=\\\"border\\_rightfree\\stextalign\\_right\\\"\\>\\<\\/td\\>\\\\n\\<td\\sclass=\\\"border\\_leftfree\\\"\\>(\\w+)\\<\\/td\\>\\\\n\\<td\\sclass=\\\"valigntop\\sborder\\stextalign\\_center\\\"\\>(\\d+\\.\\d+\\-\\d\\.\\d+)')\n",
    "my_regex_pH = re.compile(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_frame = pd.DataFrame()\n",
    "\n",
    "\n",
    "for ID in all_IDs:\n",
    "    url = get_ID_give_URL(ID)\n",
    "    html_doc = read_html(url)\n",
    "    \n",
    "    \n",
    "    if html_doc is None:\n",
    "        print(\"Something went wrong!!!  the following url seems to be wrong   ; \" , url)\n",
    "    \n",
    "    soup = BeautifulSoup(html_doc, \"lxml\")\n",
    "    list_of_extracted_data = [ID]\n",
    "    \n",
    "    \n",
    "    #first step ==> extracting phylogeny data\n",
    "    tag = \"valigntop paddingright\"\n",
    "    data = soup.find_all(\"td\", class_= tag)\n",
    "    for td in data:\n",
    "        list_of_extracted_data.append(td.text)\n",
    "        if len(list_of_extracted_data) == 9:\n",
    "            break\n",
    "        \n",
    "    #second step ==> extracting temp data\n",
    "    soup = str(soup)\n",
    "    temperature_data = my_regex_temperature.findall(soup)\n",
    "    list_of_extracted_data = list_of_extracted_data +temperature_data\n",
    "    while len(list_of_extracted_data) != 16:\n",
    "        list_of_extracted_data.append(\"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #third step ==> extracting phylogeny data\n",
    "    \n",
    "    soup = str(soup)\n",
    "    pH_data = my_regex_pH.findall(soup)\n",
    "    list_of_extracted_data = list_of_extracted_data + pH_data\n",
    "    while len(list_of_extracted_data) != 22:\n",
    "        list_of_extracted_data.append(\"\")\n",
    "    my_data_frame[ID] = pd.Series(list_of_extracted_data)\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "# transpose the dataframe\n",
    "my_data_frame = my_data_frame.T\n",
    "# naming columns\n",
    "my_data_frame = my_data_frame.rename(columns={0: 'ID',  1: 'Last LPSN update', 2: 'Domain', 3: 'Phylum', 4: 'Class', 5: 'Order', 6: 'Family', 7: 'Genus', 8: 'species', 9: 'temperature Ref 1', 10: 'temperature Ref 2', 11: 'temperature Ref 3', 12: 'temperature Ref 4', 13: 'temperature Ref 5', 14: 'temperature Ref 6', 15: 'temperature Ref 7', 16: 'pH 1', 17: 'pH 2', 18: 'pH 3', 19: 'pH 4', 20: 'pH 5', 21: 'pH 6'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP FOUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another cleaning and filling step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the cells and replacing \"NaN\" with \"#no\"\n",
    "# this will clean the dataframe for future use\n",
    "my_data_frame[\"temperature Ref 1\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"temperature Ref 2\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"temperature Ref 3\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"temperature Ref 4\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"temperature Ref 5\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"temperature Ref 6\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"temperature Ref 7\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"pH 1\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"pH 2\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"pH 3\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"pH 4\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"pH 5\"].fillna(\"#no\", inplace = True)\n",
    "my_data_frame[\"pH 6\"].fillna(\"#no\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "until now, there are 0 species with no temperature data and you can see the list of IDs with no temp data in this: list_no_temp_species_ID\n"
     ]
    }
   ],
   "source": [
    "#### in order to know the species with no temperature data  ####\n",
    "list_index_no_temp = []\n",
    "list_no_temp_species_ID = []\n",
    "\n",
    "for counter in range (0,len(my_data_frame)):\n",
    "    if (my_data_frame.iloc[counter,10] == \"#no\"):\n",
    "        list_index_no_temp.append(counter)\n",
    "        list_no_temp_species_ID.append(my_data_frame.iloc[counter,0])\n",
    "        \n",
    "# give me an overview please\n",
    "print('until now, there are', str(len(list_no_temp_species_ID)) , 'species with no temperature data and you can see the list of IDs with no temp data in this: list_no_temp_species_ID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP FIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat all the previous dataframes and producing an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making to dataframes look the same , so we can use concat()\n",
    "s = pd.Series(range(len(bacDive)))\n",
    "bacDive = bacDive.set_index([s])\n",
    "###########################################\n",
    "s = pd.Series(range(len(my_data_frame)))\n",
    "my_data_frame = my_data_frame.set_index([s])\n",
    "###########################################\n",
    "result = pd.concat([bacDive, my_data_frame], axis=1)\n",
    "\n",
    "###########################################\n",
    "#result.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP SIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this step we want to collect some data using PubMed API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating queries to download the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_species = result['Species']\n",
    "list_of_IDs = result['ID']\n",
    "\n",
    "#this code is because we have to ID columns in the result dataframe --> i should remove it in the future\n",
    "list_of_IDs = list_of_IDs.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we dont need this step here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the repeated species  (no need)\n",
    "#new_list_of_species =[]\n",
    "#for i in list_of_species:\n",
    "    #if i not in new_list_of_species:\n",
    "        #new_list_of_species.append(i)\n",
    "        \n",
    "#list_of_species = new_list_of_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# our regexes to extract pH and optimum pH (bad regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## regexes to find pH  #############################################################\n",
    "\n",
    "regex1 = r'[^p].[^i][^m][^u][^m].pH (\\d\\d?)[^\\.][^\\d]'                                          # pH 4\n",
    "regex2 = r'[^p].[^i][^m][^u][^m].pH of (\\d\\d?\\.?\\d?\\d?)\\-?(\\d?\\d?\\.?\\d?\\d?) '                   # pH of 7-11   #pH of 7\n",
    "regex3 = r'[^p].[^i][^m][^u][^m].pH (\\d\\d?\\.\\d?\\d?)'                                            # pH 4.54 \n",
    "regex4 = r'[^p].[^i][^m][^u][^m].pH (\\d\\d?\\.?\\d?\\d?) to (\\d\\d?\\.?\\d?\\d?)'                       # pH 4.54 to 5.32\n",
    "regex5 = r'[^p].[^i][^m][^u][^m].pH (\\d\\d?\\.?\\d?\\d?) and (\\d\\d?\\.?\\d?\\d?)'                      # pH 4.54 and 5.32\n",
    "regex6 = r'[^p].[^i][^m][^u][^m].pH (\\d\\d?\\.?\\d?\\d?) and pH (\\d\\d?\\.?\\d?\\d?)'                   # pH 3.23 and pH 6.5\n",
    "regex7 = r'[^p].[^i][^m][^u][^m].pH (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'                         # pH 5.33-4.23\n",
    "regex8 = r'[^p].[^i][^m][^u][^m].pH of the medium was adjusted to (\\d\\d?\\.?\\d?\\d?)'             # pH of the medium was adjusted to 6.4\n",
    "regex9 = r'[^p].[^i][^m][^u][^m].pH range.+?from (\\d\\d?\\.?\\d?\\d?) to (\\d\\d?\\.?\\d?\\d?)'          # pH range for growth at 70 \"C was from 4.4 to 7.5\n",
    "regex10 = r'[^p].[^i][^m][^u][^m].pH range.+?from (\\d\\d?\\.?\\d?\\d?) to pH (\\d\\d?\\.?\\d?\\d?)'      # pH range for growth at 70 \"C was from 4.4 to pH 7.5\n",
    "regex11 = r'[^p].[^i][^m][^u][^m].pH range.+?from (\\d\\d?\\.?\\d?\\d?) to pH (\\d\\d?\\.?\\d?\\d?)'      # pH range 6-9\n",
    "regex12 = r'from pH (\\d\\d?\\.?\\d?\\d?) to (\\d\\d?\\.?\\d?\\d?)'                                       # from pH 5?5 to 7?0\n",
    "regex13 = r'from pH (\\d\\d?\\.?\\d?\\d?) to pH (\\d\\d?\\.?\\d?\\d?)'                                    # from pH 5?5 to pH 7?0\n",
    "regex14 = r'[^p].[^i][^m][^u][^m].pH from (\\d\\d?\\.?\\d?\\d?) to pH (\\d\\d?\\.?\\d?\\d?)'              # pH from 5?5 to pH 7?0\n",
    "regex15 = r'[^p].[^i][^m][^u][^m].pH from (\\d\\d?\\.?\\d?\\d?) to (\\d\\d?\\.?\\d?\\d?)'                 # pH from 5?5 to 7?0\n",
    "regex16 = r'[^p].[^i][^m][^u][^m].pH values of (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'              # pH values of 4.8–5.8\n",
    "regex17 = r'[^p].[^i][^m][^u][^m].pH values.+?(\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'               # pH values (4.8–5.8)\n",
    "regex18 = r'[^p].[^i][^m][^u][^m].pH values of (\\d\\d?\\.?\\d?\\d?)'                                # pH values of 4.8\n",
    "regex19 = r'pH values ranging from (\\d\\d?\\.?\\d?\\d?)[ toand\\-or]+?(\\d\\d?\\.?\\d?\\d?)'              # pH values ranging from 7.5 to 9.0\n",
    "regex20 = r'[^p].[^i][^m][^u][^m].pH around (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'                 # pH around 6.0–6.5\n",
    "regex21 = r'[^p].[^i][^m][^u][^m].pH around (\\d\\d?\\.?\\d?\\d?)'                                   # pH around 6.0\n",
    "regex22 = r'[^p].[^i][^m][^u][^m].pH growth range (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'           # pH growth range 3.5-6.4\n",
    "regex23 = r'[^p].[^i][^m][^u][^m].pH range for growth[is was for of]+?(\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'    # the pH range for growth of 2.0-6.0  # the pH range for growth is 2.0-6.0   # the pH range for growth was 2.0-6.0\n",
    "regex24 = r'[^p].[^i][^m][^u][^m].pH between (\\d\\d?\\.?\\d?\\d?) and (\\d?\\d?\\.?\\d?\\d?)'                         # pH between 7.5 and 10.5 (optimum 8.8-9)\n",
    "regex25 = r'[^m][^u][^m] pH\\(\\d\\d.+?\\).+?(\\d\\d?\\.?\\d?\\d?)[ -andorto]+?(\\d?\\d[\\.]\\d?\\d?)'                     #The pH(60 degrees C) range for growth was 4.0-8.0\n",
    "\n",
    "\n",
    "######################################## regexes to find optimum pH  #############################################################\n",
    "\n",
    "\n",
    "reggex1 = r'(optimum) pH (\\d\\d?\\.?\\d?\\d?)'                                  #optimum pH 5.6\n",
    "reggex2 = r'(optimum) pH (\\d\\d?\\.?\\d?\\d?)'                                  #optimum pH 5.6\n",
    "reggex3 = r'(optimum) pH (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'                #optimum pH 5.6-6.5\n",
    "reggex4 = r'(optimum) pH (\\d\\d?\\.?\\d?\\d?) or (\\d\\d?\\.?\\d?\\d?)'              #optimum pH 5.6 or 6.5\n",
    "reggex5 = r'(optimum) pH (\\d\\d?\\.?\\d?\\d?) and (\\d\\d?\\.?\\d?\\d?)'             #optimum pH 5.6 and 6.5\n",
    "reggex6 = r'(optimum) at pH (\\d\\d?\\.?\\d?\\d?)'                               #optimum at pH 7.25\n",
    "reggex7 = r'(optimum), pH (\\d\\d?\\.?\\d?\\d?)\\-?(\\d?\\d?\\.?\\d?\\d?)'             #optimum, pH 8.0-9.0\n",
    "reggex8 = r'(optimum) pH was (\\d\\d?\\.?\\d?\\d?)'                              #optimum pH was 2.3\n",
    "reggex9 = r'(optimum) pH was (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d)'             #optimum pH was 2.3-9.2\n",
    "reggex10 = r'growing (optimally) at pH (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'  #growing optimally at pH 3.5-4.0\n",
    "reggex11 = r'ptimum pH around (\\d\\d?\\.?\\d?\\d?)'                             #optimum pH around 6.0\n",
    "reggex12 = r'ptimum pH of the medium was adjusted to (\\d\\d?\\.?\\d?\\d?)'                        #optimum pH of the medium was adjusted to 6.4\n",
    "reggex13 = r'ptimum pH range.+?from (\\d\\d?\\.?\\d?\\d?) to (\\d\\d?\\.?\\d?\\d?)'                     #optimum pH range for growth at 70 \"C was from 4.4 to 7.5\n",
    "reggex14 = r'ptimum pH range.+?from (\\d\\d?\\.?\\d?\\d?) to pH (\\d\\d?\\.?\\d?\\d?)'                  #optimum pH range for growth at 70 \"C was from 4.4 to pH 7.5\n",
    "reggex15 = r'[^p].[^i][^m][^u][^m].pH range (\\d\\d?\\.?\\d?\\d?)[ toand\\-or]+?(\\d\\d?\\.?\\d?\\d?)'   #from optimum pH 5?5 to 7?0\n",
    "reggex16 = r'from optimum pH (\\d\\d?\\.?\\d?\\d?) to (\\d\\d?\\.?\\d?\\d?)'                            #from optimum pH 5?5 to 7?0\n",
    "reggex17 = r'from optimum pH (\\d\\d?\\.?\\d?\\d?) to pH (\\d\\d?\\.?\\d?\\d?)'                         #from optimum pH 5?5 to pH 7?0\n",
    "reggex18 = r'ptimum pH from (\\d\\d?\\.?\\d?\\d?) to pH (\\d\\d?\\.?\\d?\\d?)'                          #optimum pH from 5?5 to pH 7?0\n",
    "reggex19 = r'ptimum pH values of (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'                          #optimum pH values of 4.8–5.8\n",
    "reggex20 = r'ptimum pH values.+?(\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'                           #optimum pH values (4.8–5.8)\n",
    "reggex21 = r'ptimum pH values of (\\d\\d?\\.?\\d?\\d?)'                                            #optimum pH values of 4.8 \n",
    "reggex22 = r'ptimum pH around (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'                             #optimum pH around 6.0–6.5\n",
    "reggex23 = r'ptimum pH around (\\d\\d?\\.?\\d?\\d?)'                                               #optimum pH around 6.0\n",
    "reggex24 = r'ptimum pH growth range (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'                       #optimum pH growth range 3.5-6.4\n",
    "reggex25 = r'ptimum pH range for growth of (\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d?)'                #optimum the pH range for growth of 2.0-6.0\n",
    "reggex26 = r'pH growth range \\d\\d?\\.?\\d?\\d?\\-\\d\\d?\\.?\\d?\\d?.?.?.?.?.?(optimum).*?(\\d\\d?\\.?\\d?\\d?)\\-(\\d\\d?\\.?\\d?\\d)'            #(pH growth range 3.5-6.4; optimum, 4.0-4.5) than strain KA1(T)\n",
    "reggex27 = r'pH range for growth of \\d\\d?\\.?\\d?\\d?\\-\\d\\d?\\.?\\d?\\d \\(with an (optimum) at (\\d\\d?\\.?\\d?\\d?)\\-?(\\d?\\d?\\.?\\d?\\d?)' #the pH range for growth of 2.0-6.0 (with an optimum at 3.8)\n",
    "reggex28 = r'The (optimum) growth temperature and pH were found to be \\d\\d?\\.?\\d?\\d?-\\d\\d?\\.?\\d?\\d?.+?and (\\d\\d?\\.?\\d?\\d?)-(\\d\\d?\\.?\\d?\\d?).+?respectively'\n",
    "#The optimum growth temperature and pH were found to be 25-30 °C and 5.0-7.0, respectively\n",
    "reggex29 = r'(optimal) pH of (\\d\\d?\\.?\\d?\\d?)-(\\d\\d?\\.?\\d?\\d?)'      #optimal pH of 6-8\n",
    "reggex30 = r'pH between \\d\\d?\\.?\\d?\\d? and \\d?\\d?\\.?\\d?\\d? \\((optimum) (\\d\\d?\\.?\\d?\\d?)\\-(\\d?\\d?\\.?\\d?\\d?)'\n",
    "reggex31 = r'(optimum) pH for growth was (\\d\\d?\\.?\\d?\\d?)'           #optimum pH for growth was 9.5\n",
    "reggex32 = r'(optimum) pH for growth was (\\d\\d?\\.?\\d?\\d?)[ toand\\-or]+?(\\d\\d?\\.?\\d?\\d?)'\n",
    "#optimum pH for growth was 9.5 to 3.43   #optimum pH for growth was 9.5 and 8.4    #optimum pH for growth was 9.5-3.4    #optimum pH for growth was 9.5 or 3.2\n",
    "reggex33 = r'(optimum).pH was between (\\d\\d?\\.?\\d?\\d?)[ toand\\-or]+?(\\d\\d?\\.?\\d?\\d?)'\n",
    "reggex34 = r'pH range for growth[is was for of]+?\\d\\d?\\.?\\d?\\d?\\-\\d\\d?\\.?\\d?\\d?.+?(optimum) (\\d\\d?\\.?\\d?\\d?)\\-?(\\d?\\d?\\.?\\d?\\d?)'\n",
    "reggex35 = r'(optimum) pH[ isbetween,;:was]+(\\d\\d?\\.?\\d?\\d?)[ \\-andto]+(\\d\\d?\\.?\\d?\\d?)'    #optimum pH between 7.0 and 8.5\n",
    "reggex36 = r'(optimum) pH[ isbetween,;:was]+(\\d\\d?\\.?\\d?\\d?)'\n",
    "reggex37 = r'temperature and pH for (optimum) growth were \\d+[^\\d]+(\\d\\d?\\.?\\d?\\d?)' #The temperature and pH for optimum growth were 30 °C and 7.5\n",
    "\n",
    "\n",
    "\n",
    "#####################################  make a list of regexes   #################################################\n",
    "bad_regexes = [regex1,regex2,regex3,regex4,regex5,regex6,regex7,regex8,regex9,regex10,regex11,regex12,regex13,regex14,regex15,regex16,regex17,regex18,regex19,regex20,regex21,regex22,regex23,regex24,regex25,      reggex1,reggex2,reggex3,reggex4,reggex5,reggex6,reggex7,reggex8,reggex9,reggex10,reggex11,reggex12,reggex13,reggex14,reggex15,reggex16,reggex17,reggex18,reggex19,reggex20,reggex21,reggex22,reggex23,reggex24,reggex25,reggex26,reggex27,reggex28,reggex29,reggex30,reggex31,reggex32,reggex33,reggex34,reggex35,reggex36,reggex37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more advanced kind of regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_regex_for_pH =r'(?: from | range |)(?:(?:(optimally)|(optimum)|(optimal)|(optima)|growth|(?#next step is because we dont want and/to/or before our pH))(?: |, | at |)pH(?:s|)(?: growth|)(?: (optimal)| (optimum)| (optima)|(?: |)\\(\\d.*?(?:C|c).*?\\) ?|(?: |)\\(\\d.*?degrees.*?\\) ?| range| ranged| |))(?:(?:(?: for.+?|)|(?: growth|)(?:| range(?:| for growth)| values))(?:(?: was| were| is| are)(?:.{0,30}?)|)(?:| of| at| approximately| around| between| from| ranging from)| of the medium was adjusted to)(?#from here its about digits)(?:(?: |\\(| \\()(?#here is the first pH)((?:[1][01234]|[0-9])(?:\\.\\d|\\.\\d\\d|))(?:(?#here is the seperators)(?: |–|\\-| to | and | or | and pH | or pH | to pH |\\-pH )(?#here is the second pH)((?:[1][01234]|[0-9])(?:\\.\\d|\\.\\d\\d|))|))(?#end of digits)(?#what comes after pH digits)(?:.{0,20}(optimum)(?#from here is the optimum that sometimes comes at the end of the main part, so from now the main sentence is finished)(?:(?#from here its about digits)(?:(?#here is the first pH)(?:.{0,10}?((?:[1][01234]|[0-9])(?:\\.\\d|\\.\\d\\d|)))(?:(?#here is the seperators)(?: |–|\\-| to | and | or | and pH | or pH | to pH |\\-pH )(?#here is the second pH)((?:[1][01234]|[0-9])(?:\\.\\d|\\.\\d\\d|))|)))|)(?#end of digits)(?#what comes after pH digits)(?=(?:\\)|,|;|:| |\\.))(?![c|C|°|d|%]| [c|C|°|d|%]|  [c|C|°|d|%])'\n",
    "other_regexes = r'(neutral) pH|(neutral to alkaline) pH'\n",
    "\n",
    "advanced_regexes = [general_regex_for_pH, other_regexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# last resort regex for the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this needs to be checked\n",
    "last_resort =r'(?:(opti).{0,40}|)pH.{0,80}?(?:(optimally)|(optimum)|(optimal)|(optima)|).{0,20}?\\D((?:[1][01234]|[0-9])(?:\\.\\d|\\.\\d\\d|))(?:(?#here is the seperators)(?: |–|\\-| to | and | or | and pH | or pH | to pH |\\-pH )(?#here is the second pH)((?:[1][01234]|[0-9])(?:\\.\\d|\\.\\d\\d|))|)(?=(?:\\)|,|;|:| |\\.\\D))(?![c|C|°|d|%]| [c|C|°|d|%]|  [c|C|°|d|%])'\n",
    "\n",
    "last_regexes = [last_resort]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this def gets an species name and gives a string(query) which we can later use to search pubmed\n",
    "# here we want \"nov\" to be in our title ----> nov means\n",
    "# we want pH to be in either Title or Abstract\n",
    "\n",
    "def make_pubmed_advance_search_query(species_name):\n",
    "    query = '((' + str(species_name) + '[Title]) AND (nov[Title])) AND (pH[Title/Abstract])'\n",
    "    \n",
    "    return (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this def gets a string(query include species name) and gives an abstract using pubmed API\n",
    "\n",
    "def get_abstract_from_pubmed(query):\n",
    "    \n",
    "    # Create a PubMed object that GraphQL can use to query\n",
    "    # Note that the parameters are not required but kindly requested by PubMed Central\n",
    "    # https://www.ncbi.nlm.nih.gov/pmc/tools/developers/\n",
    "    pubmed = PubMed(tool=\"MyTool\", email=\"kz.kalhor@gmail.com\")\n",
    "\n",
    "    # Execute the query against the API\n",
    "    results = pubmed.query(query, max_results=500)\n",
    "\n",
    "    # Loop over the retrieved articles\n",
    "    for article in results:\n",
    "\n",
    "        # Extract and format information from the article\n",
    "        article_id = article.pubmed_id\n",
    "        title = article.title\n",
    "        if article.keywords:\n",
    "            if None in article.keywords:\n",
    "                article.keywords.remove(None)\n",
    "            keywords = '\", \"'.join(article.keywords)\n",
    "        publication_date = article.publication_date\n",
    "        abstract = article.abstract\n",
    "\n",
    "\n",
    "        # # make a file for the next step\n",
    "        result_of_search = (\n",
    "            f'{article_id} - {publication_date} - {title}\\n \\n{abstract}\\n'\n",
    "        )\n",
    "        \n",
    "        return(result_of_search)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with this function I remove unicode characters\n",
    "# in future i had to learn a better way to remove this characters\n",
    "\n",
    "def get_abstract_make_changes(abstract):\n",
    "    abstract = abstract.replace(\"\\u2009\",' ')\n",
    "    abstract = abstract.replace.replace(\"&emsp14;\",' ')\n",
    "    abstract = abstract.replace.replace(\"?\",'-')\n",
    "    abstract = abstract.replace.replace(\"\\n\",' ')\n",
    "    abstract = abstract.replace.replace('\\u200a',' ')\n",
    "    abstract = abstract.replace.replace('\\xa0',' ')\n",
    "    abstract = abstract.replace+ '             '\n",
    "    return(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this def gets an Abstract and gives an important sentence which includes pH\n",
    "# this step is not neccessary but i need it because i want to check the results using this sentences\n",
    "\n",
    "def find_sentence_with_pH_data(abstract):\n",
    "    the_sentence_about_pH = None\n",
    "    # a is where the pH is located in the text\n",
    "    if 'pH' in abstract:\n",
    "        a = abstract.index('pH')\n",
    "        # here we selecte the surrounding text\n",
    "        s = abstract[a-300:a+300]\n",
    "        # spliting the right sentence\n",
    "        x = s.split(\". \")\n",
    "        for i in range(0,len(x)):\n",
    "            if 'pH' in x[i]:\n",
    "                the_sentence_about_pH = x[i].replace('\\u2009', ' ')  # this code removes a unicode problem\n",
    "\n",
    "        return (the_sentence_about_pH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final def to search for whatever information we want from a string\n",
    "# the string can be either the pH sentence or the complete abstract\n",
    "# it gets the 'pH_sentence' and gives a list of what_regex_find\n",
    "\n",
    "def get_sentence_give_pH_data(pH_sentence):\n",
    "    pH_sentence = str(pH_sentence)    #I did this because of an error\n",
    "    what_regex_found = []\n",
    "    for regex in regexes:\n",
    "        \n",
    "        \n",
    "        what_is_found = re.findall(regex, pH_sentence)\n",
    "        if what_is_found != []:\n",
    "            what_regex_found.append(what_is_found)\n",
    "        \n",
    "    return (what_regex_found)\n",
    "\n",
    "# this code needs a list of regexes\n",
    "# it gets a sentence as an imput\n",
    "# the output is a list of what regex found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assemble all the pervious codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first tell me which regex do you want to use??\n",
    "\n",
    "#regexes = bad_regexes\n",
    "regexes = advanced_regexes\n",
    "#regexes = last_regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a data frame for final storage\n",
    "df = pd.DataFrame(columns = ['ID', 'species_name' ,  'query' ,  'abstract' ,   'pH_sentence' , 'what_regexss_found'])\n",
    "# this list help me to find specied with no record\n",
    "list_of_species_with_no_record = []\n",
    "\n",
    "for i in range(0,len(list_of_species)):\n",
    "    ID = list_of_IDs[i]\n",
    "    species_name = list_of_species[i]\n",
    "    \n",
    "    \n",
    "    \n",
    "    query = make_pubmed_advance_search_query(species_name)\n",
    "    abstract = get_abstract_from_pubmed(query)\n",
    "    \n",
    "\n",
    "    if abstract is None:                  #this occurs when there is no search result for a query\n",
    "        list_of_species_with_no_record.append(species_name)\n",
    "        pH_sentence = '---'\n",
    "        what_regexss_found = '---'\n",
    "        \n",
    "\n",
    "    if abstract is not None:\n",
    "        pH_sentence = find_sentence_with_pH_data(abstract)\n",
    "\n",
    "        what_regexss_found = get_sentence_give_pH_data(pH_sentence)\n",
    "\n",
    "\n",
    "\n",
    "    #print (species_name , \"===================\" , query , \"++++++++++++++++++++\", abstract , \"******************\" , pH_sentence , \">>>>>>>>>>>>>>>\" , what_regex_found)\n",
    "    #print (pH_sentence , \">>>>>>>>>>>>>>>\" , what_regexss_found)\n",
    "\n",
    "    #making lists and finally a dataframe\n",
    "    list_data = [ID, species_name , query , abstract , pH_sentence ,  what_regexss_found]\n",
    "    while len (list_data) != 6:\n",
    "        list_data.append(' ')\n",
    "    #print(list_data)\n",
    "\n",
    "    data_series = pd.Series(list_data,index = df.columns)\n",
    "    df = df.append(data_series, ignore_index=True) \n",
    "\n",
    "\n",
    "df.to_csv(r'C:\\Users\\kamy\\Desktop\\final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi! , using PubMed API we found 9 species with some records and we extracted the data we need , but there is still  44 species without any records\n"
     ]
    }
   ],
   "source": [
    "print('hi! , using PubMed API we found' , len(list_of_species)-len(list_of_species_with_no_record) , 'species with some records and we extracted the data we need , but there is still ', str(len(list_of_species_with_no_record)) , 'species without any records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all the data together\n",
    "all_data_together = pd.concat([result, df], axis=1)\n",
    "######################################################\n",
    "# save the output\n",
    "all_data_together.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
