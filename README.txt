okay! here we are
this is the main text file i will document what i am going to do.
you can read the details  in the powerpoint files located in each stage


project name:
the final goal:
number of steps: 6 (until now)
tools we used: python (pandas, re, beautiful soup),  jupyter notebook, NCBI API, PubMed API, regex101, Debuggex, git, github, gitkraken


-------------------------------------------  step one  -------------------------------------------
goal: downloding a table of species from BacDive including thier ID, link, isolation source, country, tag


-------------------------------------------  step two  -------------------------------------------
goal: cleaning the dataframe we have,  filling empty cells, get rid of redundencies, removing the duplicate rows


-------------------------------------------  step three  -------------------------------------------
goal: WEB SCRAPING from BacDive, extracting taxonomic data, optimum and growth temperature, optimum and growth pH


-------------------------------------------  step four  -------------------------------------------
goal:  another cleaning step, filling the empty cells, at the end of this step we have a message to see how many species are without temperature data


-------------------------------------------  step five  -------------------------------------------
goal: concat all the previous dataframes and producing an output


-------------------------------------------  step six  -------------------------------------------
goal: data mining from PubMed, using regexes to extract data from some abstracts


 
##########################################################
future goals : the sequence(16s) and the description of sequence





-------------------------------------------  stage two  -------------------------------------------
goal:
1- to extract other data like pH range and optimum pH from BacDive
2- to mine some abstracts and collect additional pH data

